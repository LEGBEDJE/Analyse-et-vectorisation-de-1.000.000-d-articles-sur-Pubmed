{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f078ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chargement de  la liste des IDs depuis le fichier CSV \n",
    "pubmed_ids_csv = pd.read_csv(\"corpus_pubmed_ids_for_missing_abstracts_filtered_filtered_prepared.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pubmed_ids_csv.head())\n",
    "# le fichier  pubmed_ids_csv estb composé que d'une colonne de 1M d'IDS\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0418ee",
   "metadata": {},
   "source": [
    " La prochaine etape consiste a filtrer les fichiers XML afin de récupérer  que les articles\n",
    "      qui correspondent aux   IDs dans la liste avant de faire  l'analyse\n",
    "      ici j'ai deux choix soit  via le téléchargements des fichiers XML (Méthode parse_pubmed_xml sur ghithub)\n",
    "         Ce qui nécéssite le téléchargement de tous les fichiers xml qui est trés couteux en terme de temps\n",
    "         mais permet de travaillé en local\n",
    "      ou soit utiliser efetch via l'API Entrez avec Biopython détail sur la documentation de biopython.org/docs/1.75/api/Bio.Entrez.html\n",
    "     et l 'utilisation de Api sur pumed avec Id   doc  sur  https://pubmed.ncbi.nlm.nih.gov/download/#api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ec949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extration des articles correspondant via le scripts  Python utilisant l'API Entrez de NCBI\n",
    "from Bio import Entrez, Medline\n",
    "import time\n",
    "pubmed_ids = pubmed_ids_csv['pubmedid'].astype(str).tolist() \n",
    "#Configuration de  l'email pour utiliser l'API Entrez comme décrit dans la documentation https://pubmed.ncbi.nlm.nih.gov/\n",
    "Entrez.email = \"modestelgk@gmail.com\"\n",
    "# 3. Fonction pour récupérer les données des articles via efetch\n",
    "def fetch_pubmed_articles(pubmed_ids, batch_size=100):\n",
    "    articles = []\n",
    "    \n",
    "    for i in range(0, len(pubmed_ids), batch_size):\n",
    "        id_batch = pubmed_ids[i:i + batch_size]\n",
    "        ids_str = \",\".join(id_batch)\n",
    "        \n",
    "        try:\n",
    "            # Récupérer les articles via efetch\n",
    "            handle = Entrez.efetch(db=\"pubmed\", id=ids_str, rettype=\"medline\", retmode=\"text\")\n",
    "            records = Medline.parse(handle)  # Utilisation du parser Medline\n",
    "            articles.extend(list(records))\n",
    "            handle.close()\n",
    "            \n",
    "            # Pause pour éviter de surcharger l'API\n",
    "            time.sleep(0.3)  # Respecter le taux limite des requêtes\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la récupération des articles pour le lot {i}: {e}\")\n",
    "    \n",
    "    return articles\n",
    "\n",
    "# 4. Récupérer les articles en utilisant l'API Entrez\n",
    "pubmed_data = fetch_pubmed_articles(pubmed_ids)\n",
    "\n",
    "# 5. Extraire les champs pertinents\n",
    "extracted_data = []\n",
    "for record in pubmed_data:\n",
    "    pmid = record.get('PMID', '')\n",
    "    title = record.get('TI', '')\n",
    "    abstract = record.get('AB', '')\n",
    "    date = record.get('DP', '')\n",
    "    authors = \", \".join(record.get('AU', []))  # Liste des auteurs convertie en chaîne\n",
    "    \n",
    "    extracted_data.append({\n",
    "        'PMID': pmid,\n",
    "        'Title': title,\n",
    "        'Abstract': abstract,\n",
    "        'Date': date,\n",
    "        'Authors': authors\n",
    "    })\n",
    "\n",
    "print(\"je suis ici\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10054f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
